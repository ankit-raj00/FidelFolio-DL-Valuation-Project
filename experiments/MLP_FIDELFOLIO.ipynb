{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j9ovFWnNoGK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Au9PT7g6z0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jQpW06VNuqw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/FidelFolio_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBesRTI1OMKS",
        "outputId": "ba2417cb-1cd8-45a2-ae3c-4e1ae3d27343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24751, 33)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spK4h-wfONxd",
        "outputId": "2ec8f5a3-d99d-4dc6-9dda-451e8b5e9902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24751 entries, 0 to 24750\n",
            "Data columns (total 33 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Year        24751 non-null  int64  \n",
            " 1   Company     24751 non-null  object \n",
            " 2   Feature1    20914 non-null  float64\n",
            " 3   Feature2    21999 non-null  float64\n",
            " 4   Feature3    22770 non-null  float64\n",
            " 5   Feature4    24204 non-null  object \n",
            " 6   Feature5    24148 non-null  object \n",
            " 7   Feature6    24050 non-null  object \n",
            " 8   Feature7    24274 non-null  object \n",
            " 9   Feature8    24751 non-null  float64\n",
            " 10  Feature9    23514 non-null  object \n",
            " 11  Feature10   24025 non-null  float64\n",
            " 12  Feature11   24207 non-null  float64\n",
            " 13  Feature12   24292 non-null  float64\n",
            " 14  Feature13   24729 non-null  float64\n",
            " 15  Feature14   24716 non-null  float64\n",
            " 16  Feature15   24198 non-null  float64\n",
            " 17  Feature16   24625 non-null  float64\n",
            " 18  Feature17   24702 non-null  float64\n",
            " 19  Feature18   24625 non-null  float64\n",
            " 20  Feature19   24724 non-null  float64\n",
            " 21  Feature20   24384 non-null  float64\n",
            " 22  Feature21   24334 non-null  float64\n",
            " 23  Feature22   24564 non-null  float64\n",
            " 24  Feature23   24706 non-null  float64\n",
            " 25  Feature24   24705 non-null  float64\n",
            " 26  Feature25   24701 non-null  float64\n",
            " 27  Feature26   24702 non-null  float64\n",
            " 28  Feature27   24727 non-null  float64\n",
            " 29  Feature28   22719 non-null  float64\n",
            " 30   Target 1   22964 non-null  object \n",
            " 31   Target 2   21409 non-null  object \n",
            " 32   Target 3   19885 non-null  object \n",
            "dtypes: float64(23), int64(1), object(9)\n",
            "memory usage: 6.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j0rZxUs1OQni",
        "outputId": "1d16b713-9443-4c20-8d3a-42750d998439"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Company</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature1</th>\n",
              "      <td>3837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature2</th>\n",
              "      <td>2752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature3</th>\n",
              "      <td>1981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature4</th>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature5</th>\n",
              "      <td>603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature6</th>\n",
              "      <td>701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature7</th>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature8</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature9</th>\n",
              "      <td>1237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature10</th>\n",
              "      <td>726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature11</th>\n",
              "      <td>544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature12</th>\n",
              "      <td>459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature13</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature14</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature15</th>\n",
              "      <td>553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature16</th>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature17</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature18</th>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature19</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature20</th>\n",
              "      <td>367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature21</th>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature22</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature23</th>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature24</th>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature25</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature26</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature27</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature28</th>\n",
              "      <td>2032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target 1</th>\n",
              "      <td>1787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target 2</th>\n",
              "      <td>3342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target 3</th>\n",
              "      <td>4866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Year             0\n",
              "Company          0\n",
              "Feature1      3837\n",
              "Feature2      2752\n",
              "Feature3      1981\n",
              "Feature4       547\n",
              "Feature5       603\n",
              "Feature6       701\n",
              "Feature7       477\n",
              "Feature8         0\n",
              "Feature9      1237\n",
              "Feature10      726\n",
              "Feature11      544\n",
              "Feature12      459\n",
              "Feature13       22\n",
              "Feature14       35\n",
              "Feature15      553\n",
              "Feature16      126\n",
              "Feature17       49\n",
              "Feature18      126\n",
              "Feature19       27\n",
              "Feature20      367\n",
              "Feature21      417\n",
              "Feature22      187\n",
              "Feature23       45\n",
              "Feature24       46\n",
              "Feature25       50\n",
              "Feature26       49\n",
              "Feature27       24\n",
              "Feature28     2032\n",
              " Target 1     1787\n",
              " Target 2     3342\n",
              " Target 3     4866\n",
              "dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZbq6Od-OgdQ",
        "outputId": "667a43b5-83f3-4a34-edcd-bdece27df1f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Company', 'Feature1', 'Feature2', 'Feature3', 'Feature4',\n",
              "       'Feature5', 'Feature6', 'Feature7', 'Feature8', 'Feature9', 'Feature10',\n",
              "       'Feature11', 'Feature12', 'Feature13', 'Feature14', 'Feature15',\n",
              "       'Feature16', 'Feature17', 'Feature18', 'Feature19', 'Feature20',\n",
              "       'Feature21', 'Feature22', 'Feature23', 'Feature24', 'Feature25',\n",
              "       'Feature26', 'Feature27', 'Feature28', ' Target 1 ', ' Target 2 ',\n",
              "       ' Target 3 '],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "r9mzWgiTQ-mr",
        "outputId": "55f2f5a1-5a56-4c77-8d2c-80dd5fa4d7a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d0aa2fd1-3f12-4559-9fa2-a5f8b826b643\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Company</th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature2</th>\n",
              "      <th>Feature3</th>\n",
              "      <th>Feature4</th>\n",
              "      <th>Feature5</th>\n",
              "      <th>Feature6</th>\n",
              "      <th>Feature7</th>\n",
              "      <th>Feature8</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature22</th>\n",
              "      <th>Feature23</th>\n",
              "      <th>Feature24</th>\n",
              "      <th>Feature25</th>\n",
              "      <th>Feature26</th>\n",
              "      <th>Feature27</th>\n",
              "      <th>Feature28</th>\n",
              "      <th>Target 1</th>\n",
              "      <th>Target 2</th>\n",
              "      <th>Target 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1999</td>\n",
              "      <td>Hind. Unilever</td>\n",
              "      <td>15.00</td>\n",
              "      <td>65.87</td>\n",
              "      <td>54.57</td>\n",
              "      <td>41.12</td>\n",
              "      <td>45.82</td>\n",
              "      <td>123.34</td>\n",
              "      <td>0.65</td>\n",
              "      <td>33131.93</td>\n",
              "      <td>...</td>\n",
              "      <td>19.581982</td>\n",
              "      <td>1192.76</td>\n",
              "      <td>1222.04</td>\n",
              "      <td>1120.99</td>\n",
              "      <td>1091.71</td>\n",
              "      <td>1956.94</td>\n",
              "      <td>264.31</td>\n",
              "      <td>5.38</td>\n",
              "      <td>29.08</td>\n",
              "      <td>42.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999</td>\n",
              "      <td>ITC</td>\n",
              "      <td>66.00</td>\n",
              "      <td>35.77</td>\n",
              "      <td>32.29</td>\n",
              "      <td>37.91</td>\n",
              "      <td>36.37</td>\n",
              "      <td>-269.26</td>\n",
              "      <td>0.57</td>\n",
              "      <td>23632.98</td>\n",
              "      <td>...</td>\n",
              "      <td>10.904040</td>\n",
              "      <td>1040.32</td>\n",
              "      <td>1249.28</td>\n",
              "      <td>1146.99</td>\n",
              "      <td>938.03</td>\n",
              "      <td>3486.42</td>\n",
              "      <td>1252.22</td>\n",
              "      <td>-67.4</td>\n",
              "      <td>-23.41</td>\n",
              "      <td>-33.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999</td>\n",
              "      <td>Wipro</td>\n",
              "      <td>79.00</td>\n",
              "      <td>31.40</td>\n",
              "      <td>46.55</td>\n",
              "      <td>164.42</td>\n",
              "      <td>74.72</td>\n",
              "      <td>348.29</td>\n",
              "      <td>1.61</td>\n",
              "      <td>18438.55</td>\n",
              "      <td>...</td>\n",
              "      <td>44.860469</td>\n",
              "      <td>182.67</td>\n",
              "      <td>218.26</td>\n",
              "      <td>153.73</td>\n",
              "      <td>118.14</td>\n",
              "      <td>828.14</td>\n",
              "      <td>281.07</td>\n",
              "      <td>538.95</td>\n",
              "      <td>60.23</td>\n",
              "      <td>108.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1999</td>\n",
              "      <td>O N G C</td>\n",
              "      <td>37.00</td>\n",
              "      <td>13.78</td>\n",
              "      <td>11.82</td>\n",
              "      <td>6.12</td>\n",
              "      <td>3.23</td>\n",
              "      <td>6.02</td>\n",
              "      <td>1.19</td>\n",
              "      <td>16868.75</td>\n",
              "      <td>...</td>\n",
              "      <td>0.695653</td>\n",
              "      <td>4269.99</td>\n",
              "      <td>5100.39</td>\n",
              "      <td>4404.90</td>\n",
              "      <td>3574.50</td>\n",
              "      <td>32398.94</td>\n",
              "      <td>8150.14</td>\n",
              "      <td>-29.06</td>\n",
              "      <td>4.07</td>\n",
              "      <td>124.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1999</td>\n",
              "      <td>Lila Worldwide</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.14</td>\n",
              "      <td>5,715.31</td>\n",
              "      <td>-4.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1,094.90</td>\n",
              "      <td>14916.95</td>\n",
              "      <td>...</td>\n",
              "      <td>4.154480</td>\n",
              "      <td>4.59</td>\n",
              "      <td>4.77</td>\n",
              "      <td>3.09</td>\n",
              "      <td>2.91</td>\n",
              "      <td>3590.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.06</td>\n",
              "      <td>598.24</td>\n",
              "      <td>1,057.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24746</th>\n",
              "      <td>2024</td>\n",
              "      <td>Uniphos Enter.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.63</td>\n",
              "      <td>1.61</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-268.48</td>\n",
              "      <td>19.95</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>931.62</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482592</td>\n",
              "      <td>39.77</td>\n",
              "      <td>39.77</td>\n",
              "      <td>38.94</td>\n",
              "      <td>38.94</td>\n",
              "      <td>2075.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24747</th>\n",
              "      <td>2024</td>\n",
              "      <td>Semac Consul</td>\n",
              "      <td>0.13</td>\n",
              "      <td>-27.75</td>\n",
              "      <td>-33.08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6</td>\n",
              "      <td>929.59</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-31.00</td>\n",
              "      <td>-29.13</td>\n",
              "      <td>-30.87</td>\n",
              "      <td>-32.74</td>\n",
              "      <td>105.13</td>\n",
              "      <td>19.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24748</th>\n",
              "      <td>2024</td>\n",
              "      <td>Sarveshwar Foods</td>\n",
              "      <td>1.26</td>\n",
              "      <td>11.77</td>\n",
              "      <td>8.21</td>\n",
              "      <td>55.01</td>\n",
              "      <td>-100.44</td>\n",
              "      <td>140.92</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>923.02</td>\n",
              "      <td>...</td>\n",
              "      <td>4.003557</td>\n",
              "      <td>23.61</td>\n",
              "      <td>63.05</td>\n",
              "      <td>61.93</td>\n",
              "      <td>22.49</td>\n",
              "      <td>551.20</td>\n",
              "      <td>298.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24749</th>\n",
              "      <td>2024</td>\n",
              "      <td>Chemfab Alka.</td>\n",
              "      <td>0.03</td>\n",
              "      <td>10.35</td>\n",
              "      <td>6.91</td>\n",
              "      <td>35.05</td>\n",
              "      <td>29.42</td>\n",
              "      <td>-11.8</td>\n",
              "      <td>0.77</td>\n",
              "      <td>922.45</td>\n",
              "      <td>...</td>\n",
              "      <td>2.381930</td>\n",
              "      <td>61.49</td>\n",
              "      <td>63.25</td>\n",
              "      <td>40.90</td>\n",
              "      <td>39.14</td>\n",
              "      <td>410.71</td>\n",
              "      <td>20.11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24750</th>\n",
              "      <td>2024</td>\n",
              "      <td>Bodal Chemicals</td>\n",
              "      <td>0.77</td>\n",
              "      <td>3.46</td>\n",
              "      <td>1.13</td>\n",
              "      <td>142.43</td>\n",
              "      <td>4.51</td>\n",
              "      <td>-15.69</td>\n",
              "      <td>3.46</td>\n",
              "      <td>921.53</td>\n",
              "      <td>...</td>\n",
              "      <td>0.851502</td>\n",
              "      <td>65.22</td>\n",
              "      <td>119.47</td>\n",
              "      <td>58.98</td>\n",
              "      <td>4.73</td>\n",
              "      <td>1986.07</td>\n",
              "      <td>903.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24751 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0aa2fd1-3f12-4559-9fa2-a5f8b826b643')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0aa2fd1-3f12-4559-9fa2-a5f8b826b643 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0aa2fd1-3f12-4559-9fa2-a5f8b826b643');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33c320f7-f73b-44a5-997c-64839070e3d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33c320f7-f73b-44a5-997c-64839070e3d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33c320f7-f73b-44a5-997c-64839070e3d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5d5e4d71-28f9-4276-b4f5-2154c86a40da\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5d5e4d71-28f9-4276-b4f5-2154c86a40da button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Year           Company  Feature1  Feature2  Feature3  Feature4  \\\n",
              "0      1999    Hind. Unilever     15.00     65.87     54.57     41.12   \n",
              "1      1999               ITC     66.00     35.77     32.29     37.91   \n",
              "2      1999             Wipro     79.00     31.40     46.55    164.42   \n",
              "3      1999           O N G C     37.00     13.78     11.82      6.12   \n",
              "4      1999    Lila Worldwide       NaN      0.16      0.14  5,715.31   \n",
              "...     ...               ...       ...       ...       ...       ...   \n",
              "24746  2024    Uniphos Enter.       NaN      1.63      1.61       NaN   \n",
              "24747  2024      Semac Consul      0.13    -27.75    -33.08       NaN   \n",
              "24748  2024  Sarveshwar Foods      1.26     11.77      8.21     55.01   \n",
              "24749  2024     Chemfab Alka.      0.03     10.35      6.91     35.05   \n",
              "24750  2024   Bodal Chemicals      0.77      3.46      1.13    142.43   \n",
              "\n",
              "      Feature5 Feature6   Feature7  Feature8  ...  Feature22  Feature23  \\\n",
              "0        45.82   123.34       0.65  33131.93  ...  19.581982    1192.76   \n",
              "1        36.37  -269.26       0.57  23632.98  ...  10.904040    1040.32   \n",
              "2        74.72   348.29       1.61  18438.55  ...  44.860469     182.67   \n",
              "3         3.23     6.02       1.19  16868.75  ...   0.695653    4269.99   \n",
              "4        -4.41      NaN  -1,094.90  14916.95  ...   4.154480       4.59   \n",
              "...        ...      ...        ...       ...  ...        ...        ...   \n",
              "24746  -268.48    19.95      -0.09    931.62  ...   0.482592      39.77   \n",
              "24747      NaN      NaN        0.6    929.59  ...        NaN     -31.00   \n",
              "24748  -100.44   140.92      -0.15    923.02  ...   4.003557      23.61   \n",
              "24749    29.42    -11.8       0.77    922.45  ...   2.381930      61.49   \n",
              "24750     4.51   -15.69       3.46    921.53  ...   0.851502      65.22   \n",
              "\n",
              "       Feature24  Feature25  Feature26  Feature27  Feature28   Target 1   \\\n",
              "0        1222.04    1120.99    1091.71    1956.94     264.31        5.38   \n",
              "1        1249.28    1146.99     938.03    3486.42    1252.22       -67.4   \n",
              "2         218.26     153.73     118.14     828.14     281.07      538.95   \n",
              "3        5100.39    4404.90    3574.50   32398.94    8150.14      -29.06   \n",
              "4           4.77       3.09       2.91    3590.57        NaN      150.06   \n",
              "...          ...        ...        ...        ...        ...         ...   \n",
              "24746      39.77      38.94      38.94    2075.45        NaN         NaN   \n",
              "24747     -29.13     -30.87     -32.74     105.13      19.23         NaN   \n",
              "24748      63.05      61.93      22.49     551.20     298.25         NaN   \n",
              "24749      63.25      40.90      39.14     410.71      20.11         NaN   \n",
              "24750     119.47      58.98       4.73    1986.07     903.80         NaN   \n",
              "\n",
              "        Target 2    Target 3   \n",
              "0           29.08       42.37  \n",
              "1          -23.41      -33.87  \n",
              "2           60.23       108.3  \n",
              "3            4.07      124.85  \n",
              "4          598.24    1,057.39  \n",
              "...           ...         ...  \n",
              "24746         NaN         NaN  \n",
              "24747         NaN         NaN  \n",
              "24748         NaN         NaN  \n",
              "24749         NaN         NaN  \n",
              "24750         NaN         NaN  \n",
              "\n",
              "[24751 rows x 33 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "IR7SRUDOupic",
        "outputId": "5e43419c-445e-4baf-af61-7f41ac2890a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a1db98aa-5e51-46eb-bc7e-9a7384a30796\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature2</th>\n",
              "      <th>Feature3</th>\n",
              "      <th>Feature8</th>\n",
              "      <th>Feature10</th>\n",
              "      <th>Feature11</th>\n",
              "      <th>Feature12</th>\n",
              "      <th>Feature13</th>\n",
              "      <th>Feature14</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature19</th>\n",
              "      <th>Feature20</th>\n",
              "      <th>Feature21</th>\n",
              "      <th>Feature22</th>\n",
              "      <th>Feature23</th>\n",
              "      <th>Feature24</th>\n",
              "      <th>Feature25</th>\n",
              "      <th>Feature26</th>\n",
              "      <th>Feature27</th>\n",
              "      <th>Feature28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>24751.000000</td>\n",
              "      <td>20914.000000</td>\n",
              "      <td>21999.000000</td>\n",
              "      <td>22770.000000</td>\n",
              "      <td>2.475100e+04</td>\n",
              "      <td>24025.000000</td>\n",
              "      <td>24207.000000</td>\n",
              "      <td>24292.000000</td>\n",
              "      <td>2.472900e+04</td>\n",
              "      <td>24716.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>24724.000000</td>\n",
              "      <td>24384.000000</td>\n",
              "      <td>24334.000000</td>\n",
              "      <td>24564.000000</td>\n",
              "      <td>24706.000000</td>\n",
              "      <td>24705.000000</td>\n",
              "      <td>24701.000000</td>\n",
              "      <td>24702.000000</td>\n",
              "      <td>2.472700e+04</td>\n",
              "      <td>2.271900e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2012.952972</td>\n",
              "      <td>148.094357</td>\n",
              "      <td>17.857211</td>\n",
              "      <td>15.883015</td>\n",
              "      <td>9.498492e+03</td>\n",
              "      <td>128.348474</td>\n",
              "      <td>-535.925509</td>\n",
              "      <td>507.671157</td>\n",
              "      <td>1.673431e+04</td>\n",
              "      <td>1295.060045</td>\n",
              "      <td>...</td>\n",
              "      <td>3484.034354</td>\n",
              "      <td>314.059076</td>\n",
              "      <td>419.448982</td>\n",
              "      <td>5.964409</td>\n",
              "      <td>806.636171</td>\n",
              "      <td>1466.142041</td>\n",
              "      <td>1252.019445</td>\n",
              "      <td>592.415449</td>\n",
              "      <td>9.612212e+03</td>\n",
              "      <td>1.268924e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.368602</td>\n",
              "      <td>1985.689454</td>\n",
              "      <td>15.149271</td>\n",
              "      <td>21.162288</td>\n",
              "      <td>4.568186e+04</td>\n",
              "      <td>3404.341356</td>\n",
              "      <td>3369.980788</td>\n",
              "      <td>4914.354986</td>\n",
              "      <td>1.342341e+05</td>\n",
              "      <td>9379.032152</td>\n",
              "      <td>...</td>\n",
              "      <td>17050.583469</td>\n",
              "      <td>2813.130445</td>\n",
              "      <td>2516.775615</td>\n",
              "      <td>290.323524</td>\n",
              "      <td>4096.404868</td>\n",
              "      <td>7543.395905</td>\n",
              "      <td>6993.588813</td>\n",
              "      <td>3337.552197</td>\n",
              "      <td>6.984420e+04</td>\n",
              "      <td>1.095691e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1999.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>-109.440000</td>\n",
              "      <td>-808.950000</td>\n",
              "      <td>2.363000e+01</td>\n",
              "      <td>-54666.770000</td>\n",
              "      <td>-144736.580000</td>\n",
              "      <td>-97820.410000</td>\n",
              "      <td>-1.487700e+04</td>\n",
              "      <td>-1.590000</td>\n",
              "      <td>...</td>\n",
              "      <td>-104166.800000</td>\n",
              "      <td>-932.280000</td>\n",
              "      <td>-73878.100000</td>\n",
              "      <td>-1018.341463</td>\n",
              "      <td>-42309.000000</td>\n",
              "      <td>-42247.000000</td>\n",
              "      <td>-46404.300000</td>\n",
              "      <td>-61797.000000</td>\n",
              "      <td>-1.459900e+04</td>\n",
              "      <td>1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2007.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>9.030000</td>\n",
              "      <td>7.210000</td>\n",
              "      <td>3.403250e+02</td>\n",
              "      <td>-85.220000</td>\n",
              "      <td>-207.330000</td>\n",
              "      <td>6.580000</td>\n",
              "      <td>3.213800e+02</td>\n",
              "      <td>11.617500</td>\n",
              "      <td>...</td>\n",
              "      <td>173.212500</td>\n",
              "      <td>5.227500</td>\n",
              "      <td>12.570000</td>\n",
              "      <td>0.938619</td>\n",
              "      <td>32.290000</td>\n",
              "      <td>51.030000</td>\n",
              "      <td>35.160000</td>\n",
              "      <td>17.215000</td>\n",
              "      <td>3.229300e+02</td>\n",
              "      <td>6.593000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>14.830000</td>\n",
              "      <td>14.390000</td>\n",
              "      <td>1.027400e+03</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>-50.640000</td>\n",
              "      <td>65.260000</td>\n",
              "      <td>9.464900e+02</td>\n",
              "      <td>50.945000</td>\n",
              "      <td>...</td>\n",
              "      <td>528.390000</td>\n",
              "      <td>18.445000</td>\n",
              "      <td>53.595000</td>\n",
              "      <td>1.979459</td>\n",
              "      <td>108.440000</td>\n",
              "      <td>153.230000</td>\n",
              "      <td>114.710000</td>\n",
              "      <td>73.505000</td>\n",
              "      <td>9.396800e+02</td>\n",
              "      <td>3.020400e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>125.750000</td>\n",
              "      <td>23.220000</td>\n",
              "      <td>22.357500</td>\n",
              "      <td>3.910885e+03</td>\n",
              "      <td>55.420000</td>\n",
              "      <td>-6.690000</td>\n",
              "      <td>270.085000</td>\n",
              "      <td>3.328660e+03</td>\n",
              "      <td>264.327500</td>\n",
              "      <td>...</td>\n",
              "      <td>1686.272500</td>\n",
              "      <td>70.802500</td>\n",
              "      <td>193.717500</td>\n",
              "      <td>4.115079</td>\n",
              "      <td>363.430000</td>\n",
              "      <td>520.570000</td>\n",
              "      <td>404.290000</td>\n",
              "      <td>264.290000</td>\n",
              "      <td>3.213700e+03</td>\n",
              "      <td>1.378075e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2024.000000</td>\n",
              "      <td>227428.000000</td>\n",
              "      <td>444.800000</td>\n",
              "      <td>934.770000</td>\n",
              "      <td>2.014010e+06</td>\n",
              "      <td>101904.000000</td>\n",
              "      <td>21232.980000</td>\n",
              "      <td>158788.000000</td>\n",
              "      <td>6.703736e+06</td>\n",
              "      <td>398905.120000</td>\n",
              "      <td>...</td>\n",
              "      <td>793481.000000</td>\n",
              "      <td>155386.390000</td>\n",
              "      <td>69621.000000</td>\n",
              "      <td>45253.666670</td>\n",
              "      <td>155559.000000</td>\n",
              "      <td>354825.220000</td>\n",
              "      <td>350976.090000</td>\n",
              "      <td>104727.000000</td>\n",
              "      <td>5.252252e+06</td>\n",
              "      <td>5.606147e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1db98aa-5e51-46eb-bc7e-9a7384a30796')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1db98aa-5e51-46eb-bc7e-9a7384a30796 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1db98aa-5e51-46eb-bc7e-9a7384a30796');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e84d2ca3-a655-4f95-a3cd-f0257198d353\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e84d2ca3-a655-4f95-a3cd-f0257198d353')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e84d2ca3-a655-4f95-a3cd-f0257198d353 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Year       Feature1      Feature2      Feature3      Feature8  \\\n",
              "count  24751.000000   20914.000000  21999.000000  22770.000000  2.475100e+04   \n",
              "mean    2012.952972     148.094357     17.857211     15.883015  9.498492e+03   \n",
              "std        7.368602    1985.689454     15.149271     21.162288  4.568186e+04   \n",
              "min     1999.000000       0.010000   -109.440000   -808.950000  2.363000e+01   \n",
              "25%     2007.000000       7.000000      9.030000      7.210000  3.403250e+02   \n",
              "50%     2014.000000      52.000000     14.830000     14.390000  1.027400e+03   \n",
              "75%     2019.000000     125.750000     23.220000     22.357500  3.910885e+03   \n",
              "max     2024.000000  227428.000000    444.800000    934.770000  2.014010e+06   \n",
              "\n",
              "           Feature10      Feature11      Feature12     Feature13  \\\n",
              "count   24025.000000   24207.000000   24292.000000  2.472900e+04   \n",
              "mean      128.348474    -535.925509     507.671157  1.673431e+04   \n",
              "std      3404.341356    3369.980788    4914.354986  1.342341e+05   \n",
              "min    -54666.770000 -144736.580000  -97820.410000 -1.487700e+04   \n",
              "25%       -85.220000    -207.330000       6.580000  3.213800e+02   \n",
              "50%        -7.500000     -50.640000      65.260000  9.464900e+02   \n",
              "75%        55.420000      -6.690000     270.085000  3.328660e+03   \n",
              "max    101904.000000   21232.980000  158788.000000  6.703736e+06   \n",
              "\n",
              "           Feature14  ...      Feature19      Feature20     Feature21  \\\n",
              "count   24716.000000  ...   24724.000000   24384.000000  24334.000000   \n",
              "mean     1295.060045  ...    3484.034354     314.059076    419.448982   \n",
              "std      9379.032152  ...   17050.583469    2813.130445   2516.775615   \n",
              "min        -1.590000  ... -104166.800000    -932.280000 -73878.100000   \n",
              "25%        11.617500  ...     173.212500       5.227500     12.570000   \n",
              "50%        50.945000  ...     528.390000      18.445000     53.595000   \n",
              "75%       264.327500  ...    1686.272500      70.802500    193.717500   \n",
              "max    398905.120000  ...  793481.000000  155386.390000  69621.000000   \n",
              "\n",
              "          Feature22      Feature23      Feature24      Feature25  \\\n",
              "count  24564.000000   24706.000000   24705.000000   24701.000000   \n",
              "mean       5.964409     806.636171    1466.142041    1252.019445   \n",
              "std      290.323524    4096.404868    7543.395905    6993.588813   \n",
              "min    -1018.341463  -42309.000000  -42247.000000  -46404.300000   \n",
              "25%        0.938619      32.290000      51.030000      35.160000   \n",
              "50%        1.979459     108.440000     153.230000     114.710000   \n",
              "75%        4.115079     363.430000     520.570000     404.290000   \n",
              "max    45253.666670  155559.000000  354825.220000  350976.090000   \n",
              "\n",
              "           Feature26     Feature27     Feature28  \n",
              "count   24702.000000  2.472700e+04  2.271900e+04  \n",
              "mean      592.415449  9.612212e+03  1.268924e+04  \n",
              "std      3337.552197  6.984420e+04  1.095691e+05  \n",
              "min    -61797.000000 -1.459900e+04  1.000000e-02  \n",
              "25%        17.215000  3.229300e+02  6.593000e+01  \n",
              "50%        73.505000  9.396800e+02  3.020400e+02  \n",
              "75%       264.290000  3.213700e+03  1.378075e+03  \n",
              "max    104727.000000  5.252252e+06  5.606147e+06  \n",
              "\n",
              "[8 rows x 24 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "QS-Lv3Z6L3D1",
        "outputId": "16b730b3-8d84-4eb7-8700-e411ce36ffac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aa060ee0-ff67-4c0a-a4aa-698bea9ecf0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Company</th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature2</th>\n",
              "      <th>Feature3</th>\n",
              "      <th>Feature4</th>\n",
              "      <th>Feature5</th>\n",
              "      <th>Feature6</th>\n",
              "      <th>Feature7</th>\n",
              "      <th>Feature8</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature22</th>\n",
              "      <th>Feature23</th>\n",
              "      <th>Feature24</th>\n",
              "      <th>Feature25</th>\n",
              "      <th>Feature26</th>\n",
              "      <th>Feature27</th>\n",
              "      <th>Feature28</th>\n",
              "      <th>Target 1</th>\n",
              "      <th>Target 2</th>\n",
              "      <th>Target 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1999</td>\n",
              "      <td>Hind. Unilever</td>\n",
              "      <td>15.0</td>\n",
              "      <td>65.87</td>\n",
              "      <td>54.57</td>\n",
              "      <td>41.12</td>\n",
              "      <td>45.82</td>\n",
              "      <td>123.34</td>\n",
              "      <td>0.65</td>\n",
              "      <td>33131.93</td>\n",
              "      <td>...</td>\n",
              "      <td>19.581982</td>\n",
              "      <td>1192.76</td>\n",
              "      <td>1222.04</td>\n",
              "      <td>1120.99</td>\n",
              "      <td>1091.71</td>\n",
              "      <td>1956.94</td>\n",
              "      <td>264.31</td>\n",
              "      <td>5.38</td>\n",
              "      <td>29.08</td>\n",
              "      <td>42.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999</td>\n",
              "      <td>ITC</td>\n",
              "      <td>66.0</td>\n",
              "      <td>35.77</td>\n",
              "      <td>32.29</td>\n",
              "      <td>37.91</td>\n",
              "      <td>36.37</td>\n",
              "      <td>-269.26</td>\n",
              "      <td>0.57</td>\n",
              "      <td>23632.98</td>\n",
              "      <td>...</td>\n",
              "      <td>10.904040</td>\n",
              "      <td>1040.32</td>\n",
              "      <td>1249.28</td>\n",
              "      <td>1146.99</td>\n",
              "      <td>938.03</td>\n",
              "      <td>3486.42</td>\n",
              "      <td>1252.22</td>\n",
              "      <td>-67.4</td>\n",
              "      <td>-23.41</td>\n",
              "      <td>-33.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999</td>\n",
              "      <td>Wipro</td>\n",
              "      <td>79.0</td>\n",
              "      <td>31.40</td>\n",
              "      <td>46.55</td>\n",
              "      <td>164.42</td>\n",
              "      <td>74.72</td>\n",
              "      <td>348.29</td>\n",
              "      <td>1.61</td>\n",
              "      <td>18438.55</td>\n",
              "      <td>...</td>\n",
              "      <td>44.860469</td>\n",
              "      <td>182.67</td>\n",
              "      <td>218.26</td>\n",
              "      <td>153.73</td>\n",
              "      <td>118.14</td>\n",
              "      <td>828.14</td>\n",
              "      <td>281.07</td>\n",
              "      <td>538.95</td>\n",
              "      <td>60.23</td>\n",
              "      <td>108.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1999</td>\n",
              "      <td>O N G C</td>\n",
              "      <td>37.0</td>\n",
              "      <td>13.78</td>\n",
              "      <td>11.82</td>\n",
              "      <td>6.12</td>\n",
              "      <td>3.23</td>\n",
              "      <td>6.02</td>\n",
              "      <td>1.19</td>\n",
              "      <td>16868.75</td>\n",
              "      <td>...</td>\n",
              "      <td>0.695653</td>\n",
              "      <td>4269.99</td>\n",
              "      <td>5100.39</td>\n",
              "      <td>4404.90</td>\n",
              "      <td>3574.50</td>\n",
              "      <td>32398.94</td>\n",
              "      <td>8150.14</td>\n",
              "      <td>-29.06</td>\n",
              "      <td>4.07</td>\n",
              "      <td>124.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1999</td>\n",
              "      <td>Lila Worldwide</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.14</td>\n",
              "      <td>5,715.31</td>\n",
              "      <td>-4.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1,094.90</td>\n",
              "      <td>14916.95</td>\n",
              "      <td>...</td>\n",
              "      <td>4.154480</td>\n",
              "      <td>4.59</td>\n",
              "      <td>4.77</td>\n",
              "      <td>3.09</td>\n",
              "      <td>2.91</td>\n",
              "      <td>3590.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.06</td>\n",
              "      <td>598.24</td>\n",
              "      <td>1,057.39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa060ee0-ff67-4c0a-a4aa-698bea9ecf0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa060ee0-ff67-4c0a-a4aa-698bea9ecf0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa060ee0-ff67-4c0a-a4aa-698bea9ecf0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19776c18-0a69-4b79-87b8-b457acca2696\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19776c18-0a69-4b79-87b8-b457acca2696')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19776c18-0a69-4b79-87b8-b457acca2696 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Year         Company  Feature1  Feature2  Feature3  Feature4 Feature5  \\\n",
              "0  1999  Hind. Unilever      15.0     65.87     54.57     41.12    45.82   \n",
              "1  1999             ITC      66.0     35.77     32.29     37.91    36.37   \n",
              "2  1999           Wipro      79.0     31.40     46.55    164.42    74.72   \n",
              "3  1999         O N G C      37.0     13.78     11.82      6.12     3.23   \n",
              "4  1999  Lila Worldwide       NaN      0.16      0.14  5,715.31    -4.41   \n",
              "\n",
              "  Feature6   Feature7  Feature8  ...  Feature22  Feature23  Feature24  \\\n",
              "0   123.34       0.65  33131.93  ...  19.581982    1192.76    1222.04   \n",
              "1  -269.26       0.57  23632.98  ...  10.904040    1040.32    1249.28   \n",
              "2   348.29       1.61  18438.55  ...  44.860469     182.67     218.26   \n",
              "3     6.02       1.19  16868.75  ...   0.695653    4269.99    5100.39   \n",
              "4      NaN  -1,094.90  14916.95  ...   4.154480       4.59       4.77   \n",
              "\n",
              "   Feature25  Feature26  Feature27  Feature28   Target 1    Target 2   \\\n",
              "0    1120.99    1091.71    1956.94     264.31        5.38       29.08   \n",
              "1    1146.99     938.03    3486.42    1252.22       -67.4      -23.41   \n",
              "2     153.73     118.14     828.14     281.07      538.95       60.23   \n",
              "3    4404.90    3574.50   32398.94    8150.14      -29.06        4.07   \n",
              "4       3.09       2.91    3590.57        NaN      150.06      598.24   \n",
              "\n",
              "    Target 3   \n",
              "0       42.37  \n",
              "1      -33.87  \n",
              "2       108.3  \n",
              "3      124.85  \n",
              "4    1,057.39  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "OwCZAfj6L3Hc",
        "outputId": "fb204a93-b26e-472f-ba47-f8ed1f097897"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Company</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Hind. Unilever</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ITC</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wipro</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Patel Engineerin</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cummins India</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Zaggle Prepaid</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nuvama Wealth</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R R Kabel</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SignatureGlobal</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nexus Select</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2796 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Company\n",
              "Hind. Unilever      26\n",
              "ITC                 26\n",
              "Wipro               26\n",
              "Patel Engineerin    26\n",
              "Cummins India       26\n",
              "                    ..\n",
              "Zaggle Prepaid       1\n",
              "Nuvama Wealth        1\n",
              "R R Kabel            1\n",
              "SignatureGlobal      1\n",
              "Nexus Select         1\n",
              "Name: count, Length: 2796, dtype: int64"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Company'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jetqq3eZtjrp",
        "outputId": "dfd40c04-43f0-4191-bf7f-4275886538bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2796"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10yXH620iGIJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5C4X16Glyui",
        "outputId": "f4188006-4f6b-4ff7-ac17-91800f515ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRnDpn0cA009"
      },
      "source": [
        "USING MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyApAJxLA1sf",
        "outputId": "3d693624-e5c0-4d7c-df64-adb2a90fb1ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Initial Data Sample (from df) ---\n",
            "       Year  Company  Feature1  Feature2  Feature3  Feature4  Feature5  \\\n",
            "18959  2020  360 ONE    253.00      7.56      6.82     42.78      5.29   \n",
            "20893  2021  360 ONE    239.00      9.11     12.69     29.52     23.55   \n",
            "22046  2022  360 ONE      1.86     13.40     19.75       NaN       NaN   \n",
            "22474  2023  360 ONE      2.05     13.34     21.41       NaN       NaN   \n",
            "23731  2024  360 ONE      2.47     14.47     24.48       NaN       NaN   \n",
            "\n",
            "       Feature6  Feature7  Feature8  ...  FE_Feature19_Diff  \\\n",
            "18959     -4.97      2.07   8606.08  ...                NaN   \n",
            "20893      2.37      0.51  10897.02  ...        -163.729996   \n",
            "22046       NaN      0.83  14825.74  ...         195.759995   \n",
            "22474       NaN     -1.06  15342.12  ...          98.419998   \n",
            "23731       NaN     -0.28  24221.43  ...         327.779999   \n",
            "\n",
            "       FE_Feature20_Diff  FE_Feature21_Diff  FE_Feature22_Diff  \\\n",
            "18959                NaN                NaN                NaN   \n",
            "20893              -2.01         168.029999           0.976729   \n",
            "22046               1.32         208.550003                NaN   \n",
            "22474              -1.13          80.190002                NaN   \n",
            "23731              -1.07         146.279999                NaN   \n",
            "\n",
            "       FE_Feature23_Diff  FE_Feature24_Diff  FE_Feature25_Diff  \\\n",
            "18959                NaN                NaN                NaN   \n",
            "20893         200.449997         112.410004         110.459999   \n",
            "22046         265.149994         221.449997         222.679993   \n",
            "22474         103.559998         132.910004         128.339996   \n",
            "23731         168.580002         412.869995         402.540009   \n",
            "\n",
            "       FE_Feature26_Diff  FE_Feature27_Diff  FE_Feature28_Diff  \n",
            "18959                NaN                NaN                NaN  \n",
            "20893         198.500000       -3962.850098       -3761.409912  \n",
            "22046         266.380005         680.090027         730.890015  \n",
            "22474          98.989998          86.620003         976.090027  \n",
            "23731         158.250000        1553.390015        2688.260010  \n",
            "\n",
            "[5 rows x 61 columns]\n",
            "\n",
            "Initial DataFrame shape: (24164, 61)\n",
            "\n",
            "--- 1. Cleaning Column Names ---\n",
            "\n",
            "--- 2. Converting Columns to Numeric ---\n",
            "Attempted numeric conversion. 0 columns changed type.\n",
            "\n",
            "--- 3. Feature Engineering (Generic Differences) ---\n",
            "Calculating YoY differences for 56 original numeric features...\n",
            " - Created 56 absolute difference (YoY) features.\n",
            "\n",
            "--- 4. Separating Columns & Identifying Processing Features ---\n",
            "84 numeric columns identified for processing (Original + Engineered Diffs).\n",
            "\n",
            "--- 5. Performing KNN Imputation ---\n",
            "Nulls before imputation in 84 columns (Total: 274912)\n",
            "Imputation complete.\n",
            "\n",
            "--- 6. Applying Robust Scaler ---\n",
            "Scaled 84 columns (Original + Diffs) using RobustScaler.\n",
            "\n",
            "--- 7. Capping Outliers ---\n",
            "Capped outliers in 84 columns.\n",
            "\n",
            "--- 8. Applying PCA (Retaining 95% Variance) ---\n",
            "PCA applied. Reduced features from 84 to 9.\n",
            "\n",
            "--- 9. Reconstructing DataFrame with PCA Components ---\n",
            "\n",
            "--- 10. Scaling Target Variables (Separately) ---\n",
            "Applied StandardScaler to target column: 'Target 1'\n",
            "Applied StandardScaler to target column: 'Target 2'\n",
            "Applied StandardScaler to target column: 'Target 3'\n",
            "\n",
            "--- 11. Encoding Company Names ---\n",
            "Encoded 'Company' into 'Company_ID_Encoded'. Found 2728 unique companies.\n",
            "\n",
            "--- Final Preprocessed Data Sample (PCA Features, Scaled Targets) ---\n",
            "   Company  Year      PC_1      PC_2      PC_3       PC_4      PC_5  \\\n",
            "0  360 ONE  2020 -2.076216  0.487993  4.493706  20.681005  1.268908   \n",
            "1  360 ONE  2021 -3.524183  1.141271  4.552005 -48.104095  0.745999   \n",
            "2  360 ONE  2022 -5.397738  0.314996  1.712356  18.259266  1.702733   \n",
            "3  360 ONE  2023 -6.190796 -1.994069 -0.421691  -6.382337  0.119390   \n",
            "4  360 ONE  2024 -3.673609  1.082393  3.058382  19.128183  0.224798   \n",
            "\n",
            "        PC_6       PC_7       PC_8      PC_9  Target 1  Target 2  Target 3  \\\n",
            "0  29.180178  12.028052 -12.588653  1.355998 -0.532997 -0.305913 -0.217087   \n",
            "1  -1.723940 -50.800495  53.697266 -3.610799  0.004144 -0.054479  0.007409   \n",
            "2   2.893743  65.474838 -35.315258  3.143202 -0.098293 -0.002931       NaN   \n",
            "3  -1.242177 -11.218514  -5.623585  2.790367  0.086155       NaN       NaN   \n",
            "4  -0.137217  22.687111  -8.105721  1.499727       NaN       NaN       NaN   \n",
            "\n",
            "   Company_ID_Encoded  \n",
            "0                   0  \n",
            "1                   0  \n",
            "2                   0  \n",
            "3                   0  \n",
            "4                   0  \n",
            "\n",
            "Final DataFrame shape: (24164, 15)\n",
            "\n",
            "--- 12. Sorting Data ---\n",
            "\n",
            "--- 13. Defining Features for Sequence Input (Using PCA Components) ---\n",
            "Features for sequence input (9): ['PC_1', 'PC_2', 'PC_3', 'PC_4', 'PC_5']...\n",
            "\n",
            "--- 14. Defining Sequence Creation Function ---\n",
            "\n",
            "--- 15. Defining MLP Model Architecture Function ---\n",
            "\n",
            "--- 16. Starting Expanding Window Training (MLP Model) ---\n",
            "Unique years found: [np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
            "\n",
            "========== Processing Fold for Test Year: 2001 (Train up to 2000) ==========\n",
            "No valid training sequences generated. Skipping fold.\n",
            "\n",
            "========== Processing Fold for Test Year: 2002 (Train up to 2001) ==========\n",
            "Warning: Skipped 48 sequences (NaN targets).\n",
            "Generated 463 base training sequences (Input: 9 PCs, Max Len: 2).\n",
            "Prepared 488 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2002) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (44 epochs). Best Val RMSE (Scaled): 9.8348\n",
            "  --> Test RMSE for Target 1 (Original Scale): 2044.0757\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2002) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (24 epochs). Best Val RMSE (Scaled): 19.6103\n",
            "  --> Test RMSE for Target 2 (Original Scale): 4964.5288\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2002) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (44 epochs). Best Val RMSE (Scaled): 10.5442\n",
            "  --> Test RMSE for Target 3 (Original Scale): 6425.6206\n",
            "\n",
            "========== Processing Fold for Test Year: 2003 (Train up to 2002) ==========\n",
            "Warning: Skipped 98 sequences (NaN targets).\n",
            "Generated 951 base training sequences (Input: 9 PCs, Max Len: 3).\n",
            "Prepared 503 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2003) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (22 epochs). Best Val RMSE (Scaled): 11.2519\n",
            "  --> Test RMSE for Target 1 (Original Scale): 3198.8569\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2003) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (44 epochs). Best Val RMSE (Scaled): 17.4332\n",
            "  --> Test RMSE for Target 2 (Original Scale): 5832.2217\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2003) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (30 epochs). Best Val RMSE (Scaled): 11.1080\n",
            "  --> Test RMSE for Target 3 (Original Scale): 3785.3513\n",
            "\n",
            "========== Processing Fold for Test Year: 2004 (Train up to 2003) ==========\n",
            "Warning: Skipped 155 sequences (NaN targets).\n",
            "Generated 1454 base training sequences (Input: 9 PCs, Max Len: 4).\n",
            "Prepared 539 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2004) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (29 epochs). Best Val RMSE (Scaled): 13.4849\n",
            "  --> Test RMSE for Target 1 (Original Scale): 4321.7554\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2004) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (19 epochs). Best Val RMSE (Scaled): 14.7592\n",
            "  --> Test RMSE for Target 2 (Original Scale): 6833.1885\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2004) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (19 epochs). Best Val RMSE (Scaled): 11.4024\n",
            "  --> Test RMSE for Target 3 (Original Scale): 8888.0527\n",
            "\n",
            "========== Processing Fold for Test Year: 2005 (Train up to 2004) ==========\n",
            "Warning: Skipped 201 sequences (NaN targets).\n",
            "Generated 1993 base training sequences (Input: 9 PCs, Max Len: 5).\n",
            "Prepared 562 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2005) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (32 epochs). Best Val RMSE (Scaled): 12.1709\n",
            "  --> Test RMSE for Target 1 (Original Scale): 2984.4465\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2005) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (62 epochs). Best Val RMSE (Scaled): 14.9799\n",
            "  --> Test RMSE for Target 2 (Original Scale): 2043.4987\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2005) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (28 epochs). Best Val RMSE (Scaled): 11.5027\n",
            "  --> Test RMSE for Target 3 (Original Scale): 4758.8574\n",
            "\n",
            "========== Processing Fold for Test Year: 2006 (Train up to 2005) ==========\n",
            "Warning: Skipped 252 sequences (NaN targets).\n",
            "Generated 2555 base training sequences (Input: 9 PCs, Max Len: 6).\n",
            "Prepared 559 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2006) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (59 epochs). Best Val RMSE (Scaled): 11.1465\n",
            "  --> Test RMSE for Target 1 (Original Scale): 1219.1185\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2006) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (21 epochs). Best Val RMSE (Scaled): 15.0249\n",
            "  --> Test RMSE for Target 2 (Original Scale): 2583.6282\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2006) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (34 epochs). Best Val RMSE (Scaled): 14.5783\n",
            "  --> Test RMSE for Target 3 (Original Scale): 4962.6748\n",
            "\n",
            "========== Processing Fold for Test Year: 2007 (Train up to 2006) ==========\n",
            "Warning: Skipped 293 sequences (NaN targets).\n",
            "Generated 3114 base training sequences (Input: 9 PCs, Max Len: 7).\n",
            "Prepared 588 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2007) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 7.2369\n",
            "  --> Test RMSE for Target 1 (Original Scale): 1115.5266\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2007) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (42 epochs). Best Val RMSE (Scaled): 10.3119\n",
            "  --> Test RMSE for Target 2 (Original Scale): 2722.6467\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2007) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (50 epochs). Best Val RMSE (Scaled): 9.0870\n",
            "  --> Test RMSE for Target 3 (Original Scale): 3368.2854\n",
            "\n",
            "========== Processing Fold for Test Year: 2008 (Train up to 2007) ==========\n",
            "Warning: Skipped 334 sequences (NaN targets).\n",
            "Generated 3702 base training sequences (Input: 9 PCs, Max Len: 8).\n",
            "Prepared 641 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2008) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (41 epochs). Best Val RMSE (Scaled): 8.1626\n",
            "  --> Test RMSE for Target 1 (Original Scale): 1372.2422\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2008) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (44 epochs). Best Val RMSE (Scaled): 9.3706\n",
            "  --> Test RMSE for Target 2 (Original Scale): 2465.0356\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2008) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (49 epochs). Best Val RMSE (Scaled): 8.7946\n",
            "  --> Test RMSE for Target 3 (Original Scale): 8060.5391\n",
            "\n",
            "========== Processing Fold for Test Year: 2009 (Train up to 2008) ==========\n",
            "Warning: Skipped 362 sequences (NaN targets).\n",
            "Generated 4343 base training sequences (Input: 9 PCs, Max Len: 9).\n",
            "Prepared 695 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2009) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (56 epochs). Best Val RMSE (Scaled): 6.9284\n",
            "  --> Test RMSE for Target 1 (Original Scale): 1448.6750\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2009) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 6.5839\n",
            "  --> Test RMSE for Target 2 (Original Scale): 1840.0038\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2009) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (72 epochs). Best Val RMSE (Scaled): 7.3502\n",
            "  --> Test RMSE for Target 3 (Original Scale): 3703.0896\n",
            "\n",
            "========== Processing Fold for Test Year: 2010 (Train up to 2009) ==========\n",
            "Warning: Skipped 401 sequences (NaN targets).\n",
            "Generated 5038 base training sequences (Input: 9 PCs, Max Len: 10).\n",
            "Prepared 764 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2010) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 3.3677\n",
            "  --> Test RMSE for Target 1 (Original Scale): 847.5300\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2010) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (42 epochs). Best Val RMSE (Scaled): 7.9909\n",
            "  --> Test RMSE for Target 2 (Original Scale): 3689.9968\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2010) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 5.5224\n",
            "  --> Test RMSE for Target 3 (Original Scale): 3719.5430\n",
            "\n",
            "========== Processing Fold for Test Year: 2011 (Train up to 2010) ==========\n",
            "Warning: Skipped 438 sequences (NaN targets).\n",
            "Generated 5802 base training sequences (Input: 9 PCs, Max Len: 11).\n",
            "Prepared 765 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2011) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 4.5709\n",
            "  --> Test RMSE for Target 1 (Original Scale): 517.0872\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2011) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (27 epochs). Best Val RMSE (Scaled): 9.1367\n",
            "  --> Test RMSE for Target 2 (Original Scale): 4337.1934\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2011) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (58 epochs). Best Val RMSE (Scaled): 5.7373\n",
            "  --> Test RMSE for Target 3 (Original Scale): 3247.1433\n",
            "\n",
            "========== Processing Fold for Test Year: 2012 (Train up to 2011) ==========\n",
            "Warning: Skipped 481 sequences (NaN targets).\n",
            "Generated 6567 base training sequences (Input: 9 PCs, Max Len: 12).\n",
            "Prepared 799 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2012) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (59 epochs). Best Val RMSE (Scaled): 5.7613\n",
            "  --> Test RMSE for Target 1 (Original Scale): 825.6690\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2012) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 3.6174\n",
            "  --> Test RMSE for Target 2 (Original Scale): 991.5040\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2012) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (54 epochs). Best Val RMSE (Scaled): 6.5230\n",
            "  --> Test RMSE for Target 3 (Original Scale): 4819.6812\n",
            "\n",
            "========== Processing Fold for Test Year: 2013 (Train up to 2012) ==========\n",
            "Warning: Skipped 540 sequences (NaN targets).\n",
            "Generated 7366 base training sequences (Input: 9 PCs, Max Len: 13).\n",
            "Prepared 845 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2013) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (35 epochs). Best Val RMSE (Scaled): 6.3139\n",
            "  --> Test RMSE for Target 1 (Original Scale): 1224.4453\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2013) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 3.5351\n",
            "  --> Test RMSE for Target 2 (Original Scale): 644.5537\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2013) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 4.5934\n",
            "  --> Test RMSE for Target 3 (Original Scale): 5964.9019\n",
            "\n",
            "========== Processing Fold for Test Year: 2014 (Train up to 2013) ==========\n",
            "Warning: Skipped 590 sequences (NaN targets).\n",
            "Generated 8211 base training sequences (Input: 9 PCs, Max Len: 14).\n",
            "Prepared 861 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2014) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 3.4516\n",
            "  --> Test RMSE for Target 1 (Original Scale): 581.5602\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2014) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (42 epochs). Best Val RMSE (Scaled): 6.3697\n",
            "  --> Test RMSE for Target 2 (Original Scale): 3147.7024\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2014) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 3.3896\n",
            "  --> Test RMSE for Target 3 (Original Scale): 3067.5662\n",
            "\n",
            "========== Processing Fold for Test Year: 2015 (Train up to 2014) ==========\n",
            "Warning: Skipped 647 sequences (NaN targets).\n",
            "Generated 9072 base training sequences (Input: 9 PCs, Max Len: 15).\n",
            "Prepared 871 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2015) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.9278\n",
            "  --> Test RMSE for Target 1 (Original Scale): 361.1517\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2015) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.9174\n",
            "  --> Test RMSE for Target 2 (Original Scale): 612.4217\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2015) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 3.1248\n",
            "  --> Test RMSE for Target 3 (Original Scale): 947.8000\n",
            "\n",
            "========== Processing Fold for Test Year: 2016 (Train up to 2015) ==========\n",
            "Warning: Skipped 685 sequences (NaN targets).\n",
            "Generated 9943 base training sequences (Input: 9 PCs, Max Len: 16).\n",
            "Prepared 867 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2016) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.4694\n",
            "  --> Test RMSE for Target 1 (Original Scale): 285.4758\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2016) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.8010\n",
            "  --> Test RMSE for Target 2 (Original Scale): 1226.4456\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2016) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.6791\n",
            "  --> Test RMSE for Target 3 (Original Scale): 938.7828\n",
            "\n",
            "========== Processing Fold for Test Year: 2017 (Train up to 2016) ==========\n",
            "Warning: Skipped 725 sequences (NaN targets).\n",
            "Generated 10810 base training sequences (Input: 9 PCs, Max Len: 17).\n",
            "Prepared 913 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2017) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.5225\n",
            "  --> Test RMSE for Target 1 (Original Scale): 154.8875\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2017) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.5804\n",
            "  --> Test RMSE for Target 2 (Original Scale): 392.4193\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2017) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.4592\n",
            "  --> Test RMSE for Target 3 (Original Scale): 579.9863\n",
            "\n",
            "========== Processing Fold for Test Year: 2018 (Train up to 2017) ==========\n",
            "Warning: Skipped 774 sequences (NaN targets).\n",
            "Generated 11723 base training sequences (Input: 9 PCs, Max Len: 18).\n",
            "Prepared 914 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2018) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.1438\n",
            "  --> Test RMSE for Target 1 (Original Scale): 121.5691\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2018) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.2765\n",
            "  --> Test RMSE for Target 2 (Original Scale): 198.4133\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2018) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.2215\n",
            "  --> Test RMSE for Target 3 (Original Scale): 479.4140\n",
            "\n",
            "========== Processing Fold for Test Year: 2019 (Train up to 2018) ==========\n",
            "Warning: Skipped 811 sequences (NaN targets).\n",
            "Generated 12637 base training sequences (Input: 9 PCs, Max Len: 19).\n",
            "Prepared 948 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2019) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.0280\n",
            "  --> Test RMSE for Target 1 (Original Scale): 104.0246\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2019) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.1437\n",
            "  --> Test RMSE for Target 2 (Original Scale): 295.1664\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2019) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.1683\n",
            "  --> Test RMSE for Target 3 (Original Scale): 394.2791\n",
            "\n",
            "========== Processing Fold for Test Year: 2020 (Train up to 2019) ==========\n",
            "Warning: Skipped 840 sequences (NaN targets).\n",
            "Generated 13585 base training sequences (Input: 9 PCs, Max Len: 20).\n",
            "Prepared 927 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2020) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 1.9813\n",
            "  --> Test RMSE for Target 1 (Original Scale): 167.6682\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2020) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.0656\n",
            "  --> Test RMSE for Target 2 (Original Scale): 522.0602\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2020) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.0939\n",
            "  --> Test RMSE for Target 3 (Original Scale): 603.0083\n",
            "\n",
            "========== Processing Fold for Test Year: 2021 (Train up to 2020) ==========\n",
            "Warning: Skipped 866 sequences (NaN targets).\n",
            "Generated 14512 base training sequences (Input: 9 PCs, Max Len: 21).\n",
            "Prepared 995 base valid test sequences (Input: 9 PCs).\n",
            "\n",
            "--- Training MLP for Target: Target 1 (Year: 2021) ---\n",
            "Training MLP for Target 1...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 1.9165\n",
            "  --> Test RMSE for Target 1 (Original Scale): 94.4830\n",
            "\n",
            "--- Training MLP for Target: Target 2 (Year: 2021) ---\n",
            "Training MLP for Target 2...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.1421\n",
            "  --> Test RMSE for Target 2 (Original Scale): 111.6625\n",
            "\n",
            "--- Training MLP for Target: Target 3 (Year: 2021) ---\n",
            "Training MLP for Target 3...\n",
            "Training complete (75 epochs). Best Val RMSE (Scaled): 2.0753\n",
            "  --> Test RMSE for Target 3 (Original Scale): 433.8947\n",
            "\n",
            "========== Processing Fold for Test Year: 2022 (Train up to 2021) ==========\n",
            "Warning: Skipped 906 sequences (NaN targets).\n",
            "Generated 15507 base training sequences (Input: 9 PCs, Max Len: 22).\n",
            "No valid test sequences generated. Skipping prediction.\n",
            "\n",
            "========== Processing Fold for Test Year: 2023 (Train up to 2022) ==========\n",
            "Warning: Skipped 1939 sequences (NaN targets).\n",
            "Generated 15507 base training sequences (Input: 9 PCs, Max Len: 22).\n",
            "No valid test sequences generated. Skipping prediction.\n",
            "\n",
            "========== Processing Fold for Test Year: 2024 (Train up to 2023) ==========\n",
            "Warning: Skipped 3021 sequences (NaN targets).\n",
            "Generated 15507 base training sequences (Input: 9 PCs, Max Len: 22).\n",
            "No valid test sequences generated. Skipping prediction.\n",
            "\n",
            "==================== Training Loop Finished ====================\n",
            "\n",
            "Calculating Overall Performance Per Target (Original Scale) - MLP Model:\n",
            "\n",
            "--- Overall Performance for Target: Target 1 ---\n",
            "  Final Overall RMSE (Original Scale, excluding 0 NaN folds): 1402.8884\n",
            "  Final Overall MAE (Original Scale, excluding 0 NaN folds): 285.0588\n",
            "\n",
            "--- Overall Performance for Target: Target 2 ---\n",
            "  Final Overall RMSE (Original Scale, excluding 0 NaN folds): 2674.4482\n",
            "  Final Overall MAE (Original Scale, excluding 0 NaN folds): 583.3290\n",
            "\n",
            "--- Overall Performance for Target: Target 3 ---\n",
            "  Final Overall RMSE (Original Scale, excluding 0 NaN folds): 3930.2122\n",
            "  Final Overall MAE (Original Scale, excluding 0 NaN folds): 952.1766\n",
            "\n",
            "--- Script Complete ---\n"
          ]
        }
      ],
      "source": [
        "# --- [IMPORTS, CONFIGURATION as before]\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA # Keep PCA\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, LSTM, Dense, Embedding, # Keep Embedding, Dense, Input\n",
        "                                     Concatenate, Masking, Flatten, Dropout) # Keep Flatten, Concatenate, Dropout\n",
        "# Remove Masking, LSTM unless needed for a hybrid approach (not requested here)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "# --- Configuration ---\n",
        "# Preprocessing\n",
        "N_NEIGHBORS_IMPUTE = 5\n",
        "Z_SCORE_CAP = 3\n",
        "PCA_VARIANCE_RATIO = 0.95\n",
        "# Model Hyperparameters\n",
        "EMBEDDING_DIM = 16\n",
        "# MLP Specific - define layer sizes\n",
        "MLP_L1_UNITS = 128        # Units in first MLP hidden layer\n",
        "MLP_L2_UNITS = 64         # Units in second MLP hidden layer\n",
        "DENSE_UNITS = MLP_L2_UNITS # Use L2 size for consistency if needed later, otherwise remove\n",
        "DROPOUT_RATE = 0.3       # Dropout rate might need adjustment for MLP\n",
        "LEARNING_RATE = 1e-4\n",
        "# Training Parameters\n",
        "EPOCHS = 75\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION_SPLIT = 0.15\n",
        "EARLY_STOPPING_PATIENCE = 12\n",
        "REDUCE_LR_PATIENCE = 6\n",
        "MIN_HISTORY_YEARS = 2\n",
        "\n",
        "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
        "tf.get_logger().setLevel('WARN')\n",
        "tf.autograph.set_verbosity(0)\n",
        "\n",
        "# --- Load Data ---\n",
        "# Assume df is loaded\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "print(\"--- Initial Data Sample (from df) ---\")\n",
        "print(df.head())\n",
        "print(f\"\\nInitial DataFrame shape: {df.shape}\")\n",
        "\n",
        "# --- Preprocessing ---\n",
        "\n",
        "# --- Preprocessing ---\n",
        "\n",
        "# 1. Clean column names\n",
        "print(\"\\n--- 1. Cleaning Column Names ---\")\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# 2. Convert object columns to numeric\n",
        "print(\"\\n--- 2. Converting Columns to Numeric ---\")\n",
        "# (Assuming this part works as intended)\n",
        "potential_numeric_cols = df.select_dtypes(include='object').columns\n",
        "if 'Company' in potential_numeric_cols: potential_numeric_cols = potential_numeric_cols.drop('Company')\n",
        "converted_count = 0\n",
        "for col in potential_numeric_cols:\n",
        "    if col not in df.columns: continue\n",
        "    try:\n",
        "        original_type = df[col].dtype\n",
        "        converted_col = pd.to_numeric(df[col].astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
        "        if pd.api.types.is_numeric_dtype(converted_col) and converted_col.notnull().sum() > 0:\n",
        "             df[col] = converted_col\n",
        "             if df[col].dtype != original_type: converted_count += 1\n",
        "    except Exception: pass\n",
        "print(f\"Attempted numeric conversion. {converted_count} columns changed type.\")\n",
        "\n",
        "# --- [MODIFIED] Step 3: Feature Engineering (Generic Differences) ---\n",
        "print(\"\\n--- 3. Feature Engineering (Generic Differences) ---\")\n",
        "target_cols = ['Target 1', 'Target 2', 'Target 3']\n",
        "engineered_features = []\n",
        "\n",
        "# Identify original numeric features BEFORE creating differences\n",
        "original_numeric_cols = df.select_dtypes(include=np.number).columns.drop(\n",
        "    target_cols + ['Year', 'Company_ID'], errors='ignore' # Exclude targets, Year, and maybe old Company_ID\n",
        ").tolist()\n",
        "\n",
        "print(f\"Calculating YoY differences for {len(original_numeric_cols)} original numeric features...\")\n",
        "df = df.sort_values(by=['Company', 'Year']) # CRITICAL: Sort before using shift/diff\n",
        "\n",
        "for col in original_numeric_cols:\n",
        "    # Ensure the original column is numeric first\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    # Calculate absolute difference\n",
        "    diff_col_name = f'FE_{col}_Diff'\n",
        "    df[diff_col_name] = df.groupby('Company')[col].diff()\n",
        "    # Convert to float32 and add to list for processing\n",
        "    df[diff_col_name] = df[diff_col_name].astype(np.float32)\n",
        "    engineered_features.append(diff_col_name)\n",
        "\n",
        "print(f\" - Created {len(engineered_features)} absolute difference (YoY) features.\")\n",
        "\n",
        "# --- [MODIFIED] Step 4: Separate Columns & Identify ALL Features for Processing ---\n",
        "print(\"\\n--- 4. Separating Columns & Identifying Processing Features ---\")\n",
        "company_col_preserved = df['Company'].copy()\n",
        "year_col_preserved = df['Year'].copy()\n",
        "target_df_preserved = df[target_cols].copy() # Preserve original targets\n",
        "\n",
        "# Start with the original numeric cols + newly engineered diff cols\n",
        "numeric_processing_cols = original_numeric_cols + engineered_features\n",
        "\n",
        "# Remove any duplicates just in case, and ensure they exist\n",
        "numeric_processing_cols = sorted(list(set(\n",
        "    col for col in numeric_processing_cols if col in df.columns\n",
        ")))\n",
        "\n",
        "# --- Final Sanity Checks ---\n",
        "if 'Year' in numeric_processing_cols: raise ValueError(\"FATAL: 'Year' included for processing!\")\n",
        "if 'Company' in numeric_processing_cols: raise ValueError(\"FATAL: 'Company' included for processing!\")\n",
        "if any(tc in numeric_processing_cols for tc in target_cols): raise ValueError(\"FATAL: Targets included for processing!\")\n",
        "# --- End Sanity Checks ---\n",
        "\n",
        "numeric_df_to_process = df[numeric_processing_cols].copy()\n",
        "print(f\"{len(numeric_processing_cols)} numeric columns identified for processing (Original + Engineered Diffs).\")\n",
        "\n",
        "# 5. KNN Imputation (Features + Engineered Features)\n",
        "print(\"\\n--- 5. Performing KNN Imputation ---\")\n",
        "# (Impute the combined set of original features and difference features)\n",
        "if not numeric_df_to_process.empty and numeric_df_to_process.isnull().any().any():\n",
        "    null_counts_before = numeric_df_to_process.isnull().sum()\n",
        "    print(f\"Nulls before imputation in {null_counts_before[null_counts_before > 0].count()} columns (Total: {null_counts_before.sum()})\")\n",
        "    imputer = KNNImputer(n_neighbors=N_NEIGHBORS_IMPUTE)\n",
        "    numeric_df_to_process = numeric_df_to_process.astype(np.float32)\n",
        "    imputed_array = imputer.fit_transform(numeric_df_to_process)\n",
        "    numeric_df_processed = pd.DataFrame(imputed_array, columns=numeric_processing_cols, index=numeric_df_to_process.index)\n",
        "    if numeric_df_processed.isnull().sum().sum() > 0: print(\"WARNING: Nulls remain after KNN imputation!\")\n",
        "    else: print(\"Imputation complete.\")\n",
        "else:\n",
        "    print(\"No missing values found in processing columns or no columns to process.\")\n",
        "    numeric_df_processed = numeric_df_to_process\n",
        "\n",
        "# 6. Robust Scaling (Features + Engineered Features)\n",
        "print(\"\\n--- 6. Applying Robust Scaler ---\")\n",
        "cols_to_scale = numeric_processing_cols\n",
        "if cols_to_scale and not numeric_df_processed.empty:\n",
        "    feature_scaler = RobustScaler()\n",
        "    scaled_data = feature_scaler.fit_transform(numeric_df_processed[cols_to_scale])\n",
        "    numeric_df_scaled = pd.DataFrame(scaled_data, columns=cols_to_scale, index=numeric_df_processed.index)\n",
        "    print(f\"Scaled {len(cols_to_scale)} columns (Original + Diffs) using RobustScaler.\")\n",
        "else:\n",
        "    print(\"No columns identified or available for scaling.\")\n",
        "    numeric_df_scaled = numeric_df_processed\n",
        "\n",
        "# 7. Capping Outliers (on Scaled Features + Engineered Features)\n",
        "print(\"\\n--- 7. Capping Outliers ---\")\n",
        "# (Cap the combined set)\n",
        "if cols_to_scale and not numeric_df_scaled.empty:\n",
        "    numeric_df_capped = numeric_df_scaled.copy()\n",
        "    capped_cols_count = 0\n",
        "    for col in cols_to_scale:\n",
        "        col_data = numeric_df_capped[col].dropna();\n",
        "        if not col_data.empty:\n",
        "            col_mean=col_data.mean(); col_std=col_data.std()\n",
        "            if pd.notna(col_std) and col_std > 1e-6:\n",
        "                lower=col_mean-Z_SCORE_CAP*col_std; upper=col_mean+Z_SCORE_CAP*col_std\n",
        "                min_orig=numeric_df_capped[col].min(); max_orig=numeric_df_capped[col].max()\n",
        "                numeric_df_capped[col]=numeric_df_capped[col].clip(lower, upper)\n",
        "                if numeric_df_capped[col].min()>min_orig or numeric_df_capped[col].max()<max_orig: capped_cols_count+=1\n",
        "    if capped_cols_count > 0: print(f\"Capped outliers in {capped_cols_count} columns.\")\n",
        "    else: print(\"No outliers needed capping.\")\n",
        "    numeric_df_final_processed = numeric_df_capped\n",
        "else:\n",
        "    print(\"No columns available for capping.\")\n",
        "    numeric_df_final_processed = numeric_df_scaled\n",
        "\n",
        "# 8. Apply PCA (on combined imputed, scaled, capped features)\n",
        "print(f\"\\n--- 8. Applying PCA (Retaining {PCA_VARIANCE_RATIO*100:.0f}% Variance) ---\")\n",
        "n_original_features = numeric_df_final_processed.shape[1]\n",
        "if n_original_features > 0:\n",
        "    pca = PCA(n_components=PCA_VARIANCE_RATIO)\n",
        "    pca_components = pca.fit_transform(numeric_df_final_processed)\n",
        "    n_components = pca.n_components_\n",
        "    print(f\"PCA applied. Reduced features from {n_original_features} to {n_components}.\")\n",
        "    pc_cols = [f'PC_{i+1}' for i in range(n_components)]\n",
        "    pca_df = pd.DataFrame(pca_components, columns=pc_cols, index=numeric_df_final_processed.index)\n",
        "    numeric_features_for_lstm = pc_cols # LSTM will use these PC columns\n",
        "else:\n",
        "    print(\"Skipping PCA: No numeric features to process.\")\n",
        "    pca_df = pd.DataFrame(index=df.index)\n",
        "    numeric_features_for_lstm = []\n",
        "    n_components = 0\n",
        "\n",
        "# 9. Reconstruct DataFrame (Using PCA Components)\n",
        "print(\"\\n--- 9. Reconstructing DataFrame with PCA Components ---\")\n",
        "final_df = pd.concat([\n",
        "    company_col_preserved.reset_index(drop=True),\n",
        "    year_col_preserved.reset_index(drop=True),\n",
        "    pca_df.reset_index(drop=True),             # PCA components\n",
        "    target_df_preserved.reset_index(drop=True) # Original Targets\n",
        "], axis=1)\n",
        "\n",
        "# 10. Scale Target Variables\n",
        "print(\"\\n--- 10. Scaling Target Variables (Separately) ---\")\n",
        "# (Same code as before to scale targets and store scalers)\n",
        "target_scalers = {}\n",
        "final_df_scaled_targets = final_df.copy()\n",
        "for target_col in target_cols:\n",
        "    if target_col not in final_df_scaled_targets.columns: continue\n",
        "    scaler = StandardScaler()\n",
        "    target_data = final_df_scaled_targets[[target_col]].astype(np.float32)\n",
        "    valid_target_data = target_data.dropna()\n",
        "    if not valid_target_data.empty:\n",
        "        scaler.fit(valid_target_data)\n",
        "        final_df_scaled_targets[target_col] = scaler.transform(target_data)\n",
        "        target_scalers[target_col] = scaler\n",
        "        print(f\"Applied StandardScaler to target column: '{target_col}'\")\n",
        "    else: target_scalers[target_col] = None\n",
        "\n",
        "# 11. Label Encode Company\n",
        "print(\"\\n--- 11. Encoding Company Names ---\")\n",
        "le = LabelEncoder()\n",
        "final_df_scaled_targets['Company_ID_Encoded'] = le.fit_transform(final_df_scaled_targets['Company'])\n",
        "num_companies = final_df_scaled_targets['Company_ID_Encoded'].nunique()\n",
        "print(f\"Encoded 'Company' into 'Company_ID_Encoded'. Found {num_companies} unique companies.\")\n",
        "\n",
        "print(\"\\n--- Final Preprocessed Data Sample (PCA Features, Scaled Targets) ---\")\n",
        "print(final_df_scaled_targets.head())\n",
        "print(f\"\\nFinal DataFrame shape: {final_df_scaled_targets.shape}\")\n",
        "# Final check for NaNs in PCA components\n",
        "if not numeric_features_for_lstm: print(\"No PCA features to check.\")\n",
        "elif final_df_scaled_targets[numeric_features_for_lstm].isnull().any().any():\n",
        "      print(f\"\\nWARNING: NaNs detected in final PCA columns:\\n{final_df_scaled_targets[numeric_features_for_lstm].isnull().sum().sort_values(ascending=False).head()}\")\n",
        "\n",
        "\n",
        "\n",
        "# 12. Sort Data\n",
        "print(\"\\n--- 12. Sorting Data ---\")\n",
        "final_df_scaled_targets = final_df_scaled_targets.sort_values(by=['Company_ID_Encoded', 'Year']).reset_index(drop=True)\n",
        "\n",
        "# 13. Define LSTM Features (PCA Components used by sequence generator)\n",
        "print(\"\\n--- 13. Defining Features for Sequence Input (Using PCA Components) ---\")\n",
        "print(f\"Features for sequence input ({len(numeric_features_for_lstm)}): {numeric_features_for_lstm[:5]}...\")\n",
        "\n",
        "# 14. Sequence Creation Function (Keep as is)\n",
        "print(\"\\n--- 14. Defining Sequence Creation Function ---\")\n",
        "# (Function definition remains the same - it creates 3D sequence arrays)\n",
        "def create_sequences(df, numeric_cols, target_cols, company_col_id_encoded, year_col, min_hist_years=1):\n",
        "    # ... (exact same function implementation as the previous corrected answer) ...\n",
        "    all_sequences, all_company_ids, all_targets = [], [], []\n",
        "    max_len = 0; skipped_nan_sequences, skipped_nan_targets = 0, 0\n",
        "    company_groups = df.groupby(company_col_id_encoded)\n",
        "    for company_id, group in company_groups:\n",
        "        group = group.sort_values(year_col); features = group[numeric_cols].values; targets = group[target_cols].values\n",
        "        for i in range(min_hist_years, len(group)):\n",
        "            current_sequence = features[:i, :]; current_target = targets[i, :] # Get all 3 scaled targets\n",
        "            if np.isnan(current_sequence).any() or np.isinf(current_sequence).any(): skipped_nan_sequences += 1; continue\n",
        "            if np.isnan(current_target).any() or np.isinf(current_target).any(): skipped_nan_targets += 1; continue\n",
        "            all_sequences.append(current_sequence); all_company_ids.append(company_id); all_targets.append(current_target)\n",
        "            if current_sequence.shape[0] > max_len: max_len = current_sequence.shape[0]\n",
        "    if skipped_nan_sequences > 0: print(f\"Warning: Skipped {skipped_nan_sequences} sequences (NaN features).\")\n",
        "    if skipped_nan_targets > 0: print(f\"Warning: Skipped {skipped_nan_targets} sequences (NaN targets).\")\n",
        "    if not all_sequences: return np.array([]), np.array([]), np.array([]), 0\n",
        "    X_padded = pad_sequences(all_sequences, maxlen=max_len, dtype='float32', padding='pre', truncating='pre')\n",
        "    y_array = np.array(all_targets, dtype='float32'); X_comp_array = np.array(all_company_ids, dtype='int32')\n",
        "    if np.isnan(X_padded).any(): print(\"FATAL WARNING: NaNs in X_padded!\")\n",
        "    if np.isnan(y_array).any(): print(\"FATAL WARNING: NaNs in y_array!\")\n",
        "    return X_padded, X_comp_array, y_array, max_len\n",
        "\n",
        "\n",
        "# --- [MODIFIED] Model Definition (MLP with 2 Hidden Layers) ---\n",
        "print(\"\\n--- 15. Defining MLP Model Architecture Function ---\")\n",
        "def build_mlp_model(max_sequence_length, num_numeric_features, num_companies, num_targets_out, # num_targets_out will be 1\n",
        "                    embedding_dim=EMBEDDING_DIM, mlp_l1_units=MLP_L1_UNITS, mlp_l2_units=MLP_L2_UNITS,\n",
        "                    dropout_rate=DROPOUT_RATE, learning_rate=LEARNING_RATE):\n",
        "    \"\"\"Builds a 2-hidden-layer MLP model that accepts sequence input (by flattening).\"\"\"\n",
        "\n",
        "    # Input layer for sequences (will be flattened)\n",
        "    sequence_input = Input(shape=(max_sequence_length, num_numeric_features), name='Sequence_Input')\n",
        "    # Input layer for company ID\n",
        "    company_input = Input(shape=(1,), name='Company_Input')\n",
        "\n",
        "    # --- Flatten the sequence input ---\n",
        "    # This converts (batch, timesteps, features) to (batch, timesteps * features)\n",
        "    # Note: This treats padded steps the same as real steps after flattening.\n",
        "    flattened_sequence = Flatten(name='Flatten_Sequence')(sequence_input)\n",
        "\n",
        "    # --- Company Embedding Branch ---\n",
        "    company_emb = Embedding(input_dim=num_companies, output_dim=embedding_dim,\n",
        "                            embeddings_initializer='he_normal', name='Company_Embedding')(company_input)\n",
        "    company_emb_flat = Flatten(name='Flatten_Embedding')(company_emb)\n",
        "\n",
        "    # --- Combine Flattened Sequence and Company Embedding ---\n",
        "    merged = Concatenate(name='Concatenate_FlatSeq_Embedding')([flattened_sequence, company_emb_flat])\n",
        "\n",
        "    # --- MLP Layers ---\n",
        "    # Hidden Layer 1\n",
        "    x = Dense(mlp_l1_units, activation='relu', kernel_initializer='he_normal', name='MLP_Hidden_1')(merged)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    # Hidden Layer 2\n",
        "    x = Dense(mlp_l2_units, activation='relu', kernel_initializer='he_normal', name='MLP_Hidden_2')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Output Layer (Single neuron for regression per target)\n",
        "    output = Dense(num_targets_out, name='Output_Layer')(x)\n",
        "\n",
        "    # --- Build and Compile Model ---\n",
        "    model = Model(inputs=[sequence_input, company_input], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='mse',\n",
        "                  metrics=[RootMeanSquaredError(name='rmse')])\n",
        "    return model\n",
        "\n",
        "\n",
        "# --- Custom Training Loop (Using MLP Model) ---\n",
        "print(\"\\n--- 16. Starting Expanding Window Training (MLP Model) ---\")\n",
        "results = {}\n",
        "unique_years = sorted(final_df_scaled_targets['Year'].unique())\n",
        "print(f\"Unique years found: {unique_years}\")\n",
        "\n",
        "if len(unique_years) <= MIN_HISTORY_YEARS:\n",
        "    print(f\"Not enough distinct years ({len(unique_years)}) for training.\")\n",
        "else:\n",
        "    # Outer loop: Iterate through years\n",
        "    for test_year_index in range(MIN_HISTORY_YEARS, len(unique_years)):\n",
        "        test_year = unique_years[test_year_index]; train_end_year = unique_years[test_year_index - 1]\n",
        "        print(f\"\\n{'='*10} Processing Fold for Test Year: {int(test_year)} (Train up to {int(train_end_year)}) {'='*10}\")\n",
        "\n",
        "        # 1. Filter & Create base sequences (using PCA columns)\n",
        "        train_df = final_df_scaled_targets[final_df_scaled_targets['Year'] <= train_end_year].copy()\n",
        "        X_seq_train, X_cid_train, y_train_scaled_all, max_seq_len_train = create_sequences(\n",
        "            train_df, numeric_features_for_lstm, target_cols, 'Company_ID_Encoded', 'Year', min_hist_years=MIN_HISTORY_YEARS)\n",
        "        if X_seq_train.shape[0] == 0 or max_seq_len_train == 0: print(f\"No valid training sequences generated. Skipping fold.\"); continue\n",
        "        print(f\"Generated {X_seq_train.shape[0]} base training sequences (Input: {X_seq_train.shape[-1]} PCs, Max Len: {max_seq_len_train}).\")\n",
        "\n",
        "        # 2. Prepare base test sequences\n",
        "        test_sequences, test_company_ids, test_actuals_scaled_all = [], [], []\n",
        "        # ... (same NaN-checking loop as before) ...\n",
        "        test_candidate_df=final_df_scaled_targets[final_df_scaled_targets['Year']<=test_year].copy()\n",
        "        for company_id, group in test_candidate_df.groupby('Company_ID_Encoded'):\n",
        "            if test_year in group['Year'].values:\n",
        "                 group_hist=group[group['Year']<=train_end_year]\n",
        "                 if not group_hist.empty and len(group_hist)>=MIN_HISTORY_YEARS:\n",
        "                     current_sequence=group_hist[numeric_features_for_lstm].values\n",
        "                     actual_targets_scaled=group[group['Year']==test_year][target_cols].values.flatten()\n",
        "                     if np.isnan(current_sequence).any() or np.isinf(current_sequence).any(): continue\n",
        "                     if np.isnan(actual_targets_scaled).any() or np.isinf(actual_targets_scaled).any(): continue\n",
        "                     test_sequences.append(current_sequence); test_company_ids.append(company_id); test_actuals_scaled_all.append(actual_targets_scaled)\n",
        "        if not test_sequences: print(f\"No valid test sequences generated. Skipping prediction.\"); continue\n",
        "        X_seq_test = pad_sequences(test_sequences, maxlen=max_seq_len_train, dtype='float32', padding='pre', truncating='pre')\n",
        "        X_cid_test = np.array(test_company_ids, dtype='int32')\n",
        "        y_test_actual_scaled_all = np.array(test_actuals_scaled_all, dtype='float32')\n",
        "        print(f\"Prepared {X_seq_test.shape[0]} base valid test sequences (Input: {X_seq_test.shape[-1]} PCs).\")\n",
        "\n",
        "        # --- Inner loop: Train separate MLP model for each target ---\n",
        "        results[test_year] = {}\n",
        "        for target_idx, target_name in enumerate(target_cols):\n",
        "            print(f\"\\n--- Training MLP for Target: {target_name} (Year: {int(test_year)}) ---\")\n",
        "\n",
        "            y_train_target_scaled = y_train_scaled_all[:, target_idx]\n",
        "            y_test_actual_target_scaled = y_test_actual_scaled_all[:, target_idx]\n",
        "            if target_name not in target_scalers or target_scalers[target_name] is None: print(f\"Scaler for {target_name} not found. Skipping.\"); continue\n",
        "\n",
        "            # Build MLP model (passing n_components)\n",
        "            current_n_features = n_components if numeric_features_for_lstm else 0\n",
        "            if current_n_features == 0: print(\"No PCA features to train on. Skipping model.\"); continue\n",
        "\n",
        "            # Call the new MLP builder function\n",
        "            model = build_mlp_model(\n",
        "                max_sequence_length=max_seq_len_train,\n",
        "                num_numeric_features=current_n_features, # Features per time step (used by Flatten)\n",
        "                num_companies=num_companies,\n",
        "                num_targets_out=1 # Single output for this target\n",
        "            )\n",
        "            # Optional: Print summary only once\n",
        "            # if test_year_index == MIN_HISTORY_YEARS and target_idx == 0: model.summary()\n",
        "\n",
        "\n",
        "            # Define Callbacks\n",
        "            early_stopping = EarlyStopping(monitor='val_rmse', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True, verbose=0)\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.2, patience=REDUCE_LR_PATIENCE, min_lr=1e-6, verbose=0)\n",
        "\n",
        "            # Train model\n",
        "            print(f\"Training MLP for {target_name}...\")\n",
        "            history = model.fit([X_seq_train, X_cid_train.reshape(-1, 1)], y_train_target_scaled, # Still provide sequence input\n",
        "                                epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT,\n",
        "                                callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "            epochs_trained = len(history.history['loss']); best_val_rmse = min(history.history.get('val_rmse', [np.inf]))\n",
        "            print(f\"Training complete ({epochs_trained} epochs). Best Val RMSE (Scaled): {best_val_rmse:.4f}\")\n",
        "\n",
        "            # Predict (scaled)\n",
        "            predictions_scaled = model.predict([X_seq_test, X_cid_test.reshape(-1, 1)], verbose=0) # Still provide sequence input\n",
        "\n",
        "            # Inverse Transform\n",
        "            scaler_t = target_scalers[target_name]\n",
        "            try:\n",
        "                 predictions_original = scaler_t.inverse_transform(predictions_scaled).flatten()\n",
        "                 y_test_actual_original = scaler_t.inverse_transform(y_test_actual_target_scaled.reshape(-1, 1)).flatten()\n",
        "            except Exception as e:\n",
        "                 print(f\"ERROR during inverse transform for {target_name}: {e}. Storing NaNs.\")\n",
        "                 predictions_original = np.full(predictions_scaled.shape[0], np.nan)\n",
        "                 y_test_actual_original = np.full(y_test_actual_target_scaled.shape[0], np.nan)\n",
        "\n",
        "            # Store results\n",
        "            results[test_year][target_name] = {'predictions_original': predictions_original, 'actuals_original': y_test_actual_original}\n",
        "\n",
        "            # Evaluate fold performance (Original Scale)\n",
        "            if np.isnan(predictions_original).any() or np.isnan(y_test_actual_original).any(): fold_rmse_orig = np.nan\n",
        "            else: fold_rmse_orig = np.sqrt(np.mean((predictions_original - y_test_actual_original)**2))\n",
        "            print(f\"  --> Test RMSE for {target_name} (Original Scale): {fold_rmse_orig:.4f}\")\n",
        "\n",
        "            # Clean up memory\n",
        "            del model; tf.keras.backend.clear_session(); gc.collect()\n",
        "\n",
        "# --- Post-Loop Analysis (Separated per target) ---\n",
        "print(f\"\\n{'='*20} Training Loop Finished {'='*20}\")\n",
        "# (Exact same post-loop analysis code as previous answer to print RMSE/MAE per target)\n",
        "if results:\n",
        "    print(\"\\nCalculating Overall Performance Per Target (Original Scale) - MLP Model:\")\n",
        "    for target_idx, target_name in enumerate(target_cols):\n",
        "        print(f\"\\n--- Overall Performance for Target: {target_name} ---\")\n",
        "        all_actuals_orig_list = []; all_predictions_orig_list = []; nan_folds_report = []\n",
        "        for year in sorted(results.keys()):\n",
        "            if year in results and target_name in results[year]:\n",
        "                data = results[year][target_name]; pred_orig = data['predictions_original']; act_orig = data['actuals_original']\n",
        "                if np.isnan(pred_orig).any() or np.isinf(pred_orig).any() or np.isnan(act_orig).any() or np.isinf(act_orig).any():\n",
        "                    nan_folds_report.append(int(year))\n",
        "                else: all_actuals_orig_list.append(act_orig); all_predictions_orig_list.append(pred_orig)\n",
        "        if all_actuals_orig_list:\n",
        "            all_actuals_np = np.concatenate(all_actuals_orig_list, axis=0); all_predictions_np = np.concatenate(all_predictions_orig_list, axis=0)\n",
        "            final_mse = np.mean((all_predictions_np - all_actuals_np)**2); final_rmse = np.sqrt(final_mse)\n",
        "            final_mae = np.mean(np.abs(all_predictions_np - all_actuals_np))\n",
        "            print(f\"  Final Overall RMSE (Original Scale, excluding {len(nan_folds_report)} NaN folds): {final_rmse:.4f}\")\n",
        "            print(f\"  Final Overall MAE (Original Scale, excluding {len(nan_folds_report)} NaN folds): {final_mae:.4f}\")\n",
        "            if nan_folds_report: print(f\"  NaN results occurred for this target in test years: {nan_folds_report}\")\n",
        "        else: print(f\"  No valid (non-NaN) predictions in original scale generated for {target_name}.\")\n",
        "else: print(\"No results generated.\")\n",
        "\n",
        "print(\"\\n--- Script Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXSis5d4eqnH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeJBjMuierMx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBfdtjt6erQV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
